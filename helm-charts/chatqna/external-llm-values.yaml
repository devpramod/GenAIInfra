# External LLM configuration override
externalLLM:
  enabled: true  # Enable external LLM service
  LLM_SERVER_HOST_IP: "your-llm-endpoint-here"  # External LLM service host
  LLM_MODEL: "gpt-4"  # LLM model to use
  OPENAI_API_KEY: "insert-your-openai-key-here"  # OpenAI API key for authentication

# Disable internal LLM services when using external LLM
llm-uservice:
  enabled: false

vllm:
  enabled: false

tgi:
  enabled: false
