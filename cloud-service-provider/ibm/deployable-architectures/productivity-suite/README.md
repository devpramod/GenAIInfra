# OPEA Productivity Suite for IBM Cloud VPC via Intel® AI for Enterprise Inference

A Terraform module for deploying the OPEA (Open Platform for Enterprise AI) Productivity Suite on IBM Cloud VPC infrastructure. This solution provides a comprehensive set of AI-powered productivity tools built on top of secure, scalable, and OpenAI-compliant LLM endpoints generated by Intel® AI for Enterprise Inference, enabling enterprises to leverage generative AI capabilities for document processing, code generation, and a conversational assistant.

## Overview

The OPEA Productivity Suite deploys a collection of microservices that provide various AI-powered capabilities:

- **ChatQnA**: Conversational AI with document retrieval capabilities (RAG)
- **DocSum**: Document summarization service
- **CodeGen**: AI-powered code generation and assistance
- **Authentication**: Integrated Keycloak for identity and access management

The deployment is fully automated using Terraform and Helm, allowing for consistent and repeatable deployments across environments. This module handles both the infrastructure provisioning (IBM Cloud VPC and Kubernetes Service) and application deployment.

## Quick Start

1. Clone this repository
2. Configure your IBM Cloud credentials
3. Set required variables in `terraform.tfvars`
4. Initialize and apply the Terraform configuration:

```bash
terraform init
terraform apply
```

## Prerequisites

- IBM Cloud account
- IBM Cloud API key
- Terraform ≥ 1.0.0
- Access to Intel-based virtual servers

- Helm Charts from opea-project/GenAIInfra v1.2 (Provided in the module)

## Architecture

```mermaid
---
config:
  flowchart:
    nodeSpacing: 300
    rankSpacing: 120
    curve: basis
  themeVariables:
    fontSize: 50px
---
flowchart LR
    %% Colors %%
    classDef blue fill:#ADD8E6,stroke:#ADD8E6,stroke-width:2px,fill-opacity:0.5
    classDef orange fill:#FBAA60,stroke:#ADD8E6,stroke-width:2px,fill-opacity:0.5
    classDef orchid fill:#C26DBC,stroke:#ADD8E6,stroke-width:2px,fill-opacity:0.5
    classDef invisible fill:transparent,stroke:transparent;
    style ChatQnA-MegaService stroke:#000000
    style DocSum-MegaService stroke:#000000
    style CodeGen-MegaService stroke:#000000
    style MultiModal-MegaService stroke:#000000
    style UserInterface stroke:#000000

    %% Subgraphs %%
    subgraph ChatQnA-MegaService["ChatQnA MegaService "]
        direction LR
        EM([Embedding MicroService]):::blue
        RET([Retrieval MicroService]):::blue
        RER([Rerank MicroService]):::blue
        LLM([LLM MicroService]):::blue
    end
    subgraph DocSum-MegaService["DocSum MegaService "]
        direction LR
        LLM_D([LLM MicroService]):::blue
    end
    subgraph CodeGen-MegaService["CodeGen MegaService "]
        direction LR
        LLM_CG([LLM MicroService]):::blue
    end
    subgraph UserInterface[" User Interface "]
        direction LR
        a([User Input Query]):::orchid
        Ingest([Ingest data]):::orchid
        UI([UI server<br>]):::orchid
    end
    TEI_RER{{Reranking service<br>}}
    TEI_EM{{Embedding service <br>}}
    VDB{{Vector DB<br><br>}}:::blue
    R_RET{{Retriever service <br>}}
    DP([Data Preparation MicroService]):::blue

    %% Gateway components
    GW_C([ChatQnA GateWay<br>]):::orange
    GW_D([DocSum GateWay<br>]):::orange
    GW_CG([CodeGen GateWay<br>]):::orange
    GW_MM([MultiModal GateWay<br>]):::orange

    %% LLM Services
    LLM_gen_C{{<span style='font-size:0.8em'>Intel® AI for Enterprise Inference LLM Service</span> <br>}}
    LLM_gen_D{{<span style='font-size:0.8em'>Intel® AI for Enterprise Inference LLM Service</span> <br>}}
    LLM_gen_CG{{<span style='font-size:0.8em'>Intel® AI for Enterprise Inference LLM Service</span> <br>}}
    LLM_gen_MM{{<span style='font-size:0.8em'>Intel® AI for Enterprise Inference LLM Service</span> <br>}}
    PR([Prompt Registry MicroService]):::blue
    CH([Chat History MicroService]):::blue
    MDB{{Mongo DB<br><br>}}


    %% Data Preparation flow
    %% Ingest data flow
    direction LR
    Ingest[Ingest data] --> UI
    UI --> DP
    DP <-.-> TEI_EM

    %% Questions interaction
    direction LR
    a[User Input Query] --> UI
    UI <--> GW_C
    GW_C <==> ChatQnA-MegaService
    EM ==> RET
    RET ==> RER
    RER ==> LLM


    %% Vector DB interaction (moved up)
    direction TB
    R_RET <-.-> VDB
    DP <-.-> VDB

    %% Embedding service flow
    direction LR
    EM <-.-> TEI_EM
    RET <-.-> R_RET
    RER <-.-> TEI_RER
    LLM <-.-> LLM_gen_C

    %% Questions interaction
    direction LR
    UI --> GW_D
    GW_D <==> DocSum-MegaService


    %% Embedding service flow
    direction LR
    LLM_D <-.-> LLM_gen_D

    %% Questions interaction
    direction LR
    UI --> GW_CG
    GW_CG <==> CodeGen-MegaService


    %% Embedding service flow
    direction LR
    LLM_CG <-.-> LLM_gen_CG

    %% Questions interaction
    direction LR
    UI --> GW_MM
    GW_MM <==> MultiModal-MegaService

    %% Multi-Modal service flow
    direction LR
    LLM_MM <-.-> LLM_gen_MM

    %% Questions interaction
    direction LR
    UI --> PR

    %% Embedding service flow
    direction LR
    PR <-.-> MDB

    %% Questions interaction
    direction LR
    UI --> CH

    %% Embedding service flow
    direction LR
    CH <-.-> MDB

```

The solution architecture consists of two main layers:

### Infrastructure Layer

- IBM Cloud VPC with public and private subnets
- IBM Kubernetes Service (IKS) cluster deployed within the VPC
- Storage volumes for persistent data
- Load balancers for service exposure

### Application Layer

The OPEA Productivity Suite follows a microservices architecture with these key components:

1. **UI Layer**: Unified interface for all services
2. **Gateway Layer**: Central ingress with authentication
3. **Megaservices**:
   - **ChatQnA**: Conversational AI with RAG capabilities
   - **DocSum**: Document summarization
   - **CodeGen**: Code generation assistance
4. **Shared Infrastructure**:
   - Keycloak for authentication
   - Vector databases for document retrieval
   - MongoDB for data persistence

Each megaservice comprises multiple specialized microservices:

### ChatQnA Components

- LLM Service
- Embedding Service
- Retriever Service
- Reranking Service

### DocSum Components

- Document Processing
- Summarization Service

### CodeGen Components

- Code Understanding
- LLM Code Generation

## Modules

The solution includes the following Terraform modules:

- `ibm-cloud-vpc`: Provisions the IBM Cloud VPC infrastructure and IKS cluster
- `chatqna`: Deploys the ChatQnA megaservice
- `codegen`: Deploys the CodeGen megaservice
- `docsum`: Deploys the DocSum megaservice
- 'chathistory': Deploys the chathistory service
- 'prompt': Deploys the prompt registry service

Supporting infrastructure:

- Keycloak: Identity and access management
- Nginx: Central gateway for all services
- UI: Unified user interface

## Resource Requirements

The infrastructure provisioning creates IBM Cloud VPC resources with the following specifications:

- **Compute**: Intel-based virtual servers (recommended: 32+ vCPU cores)
- **Memory**: Minimum 64GB RAM for full deployment
- **Storage**: 100GB+ for model storage
- **Networking**: VPC with public and private subnets
- **Kubernetes**: IBM Kubernetes Service (IKS) cluster with worker nodes provisioned in the VPC

## Inputs

### Core Infrastructure Variables

| Name                                        | Description                            | Type   | Required |
| ------------------------------------------- | -------------------------------------- | ------ | :------: |
| ibmcloud_api_key                            | IBM Cloud API key                      | string |   yes    |
| HuggingFace Token                           | HF Token with access to desired models | string |   yes    |
| Intel® AI for Enterprise Inference API Key | API Keys for LLM endpoints             | string |   yes    |
| email                                       | IBM Cloud email address                | string |    no    |
| region                                      | IBM Cloud region                       | string |   yes    |
| vpc_name                                    | Name of the VPC to create              | string |   yes    |
| cluster_name                                | Name of the IKS cluster                | string |   yes    |
| worker_count                                | Number of worker nodes                 | number |   yes    |
| machine_type                                | Worker node instance profile           | string |   yes    |
| cluster_version                             | Kubernetes version for IKS cluster     | string |   yes    |

### Application Variables

| Name                         | Description                             | Type   | Required |
| ---------------------------- | --------------------------------------- | ------ | :------: |
| chatqna_model_dir            | Directory path for ChatQNA models       | string |   yes    |
| chatqna_helm_chart_path      | Path to the ChatQNA Helm chart          | string |   yes    |
| chatqna_model_name           | Name of the main ChatQNA model          | string |   yes    |
| chatqna_embedding_model_name | Name of the embedding model for ChatQNA | string |   yes    |
| chatqna_reranker_model_name  | Name of the reranker model for ChatQNA  | string |   yes    |
| chatqna_llm_service_host_ip  | LLM Service Host IP for ChatQNA         | string |   yes    |
| codegen_model_dir            | Directory path for Codegen models       | string |   yes    |
| codegen_helm_chart_path      | Path to the Codegen Helm chart          | string |   yes    |
| codegen_model_name           | Name of the Codegen model               | string |   yes    |
| codegen_llm_service_host_ip  | LLM Service Host IP for Codegen         | string |   yes    |
| docsum_model_dir             | Directory path for Docsum models        | string |   yes    |
| docsum_helm_chart_path       | Path to the Docsum Helm chart           | string |   yes    |
| docsum_model_name            | Name of the Docsum model                | string |   yes    |
| docsum_llm_service_host_ip   | LLM Service Host IP for Docsum          | string |   yes    |
| nginx_helm_chart_path        | Path to the Nginx Helm chart            | string |   yes    |
| ui_helm_chart_path           | Path to the UI Helm chart               | string |   yes    |

## Outputs

### Infrastructure Outputs

| Name                     | Description                           |
| ------------------------ | ------------------------------------- |
| vpc_id                   | ID of the created VPC                 |
| cluster_id               | ID of the provisioned IKS cluster     |
| cluster_endpoint         | API endpoint URL for the IKS cluster  |
| cluster_ingress_hostname | Ingress hostname for the IKS cluster  |
| kubeconfig_path          | Path to the generated kubeconfig file |

### Application Outputs

| Name              | Description                         |
| ----------------- | ----------------------------------- |
| keycloak_endpoint | LoadBalancer endpoint for Keycloak  |
| ui_endpoint       | UI Service Endpoint                 |
| deployment_status | Status of all deployments           |
| chatqna_namespace | Namespace where ChatQnA is deployed |
| codegen_namespace | Namespace where CodeGen is deployed |
| docsum_namespace  | Namespace where DocSum is deployed  |

## Configuration Options

### Infrastructure Configuration

The IBM Cloud VPC and IKS infrastructure can be customized through:

- Region and zone selection
- VPC networking configuration
- Worker node machine types and counts
- Storage class and capacity options
- Kubernetes version selection

### Application Configuration

The application deployment can be customized through various feature flags:

- Enable/disable specific components (UI, Embedding, Re-ranking etc.)
- Configure model sources and endpoints
- Set authentication parameters
- Customize resource allocation

## Security Considerations

### Infrastructure Security

- VPC security groups automatically configured to restrict network access
- Private subnets used for worker nodes with controlled ingress/egress
- Kubernetes RBAC enabled by default
- IBM cloud IAM integration for cluster access control

### Application Security

- Keycloak is configured with default admin credentials (should be changed in production)
- Access to services is protected through authentication
- Network policies applied to restrict pod-to-pod communication
- For production deployments, consider using a certificate manager for TLS
